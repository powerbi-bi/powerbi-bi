---
layout:     post
header-img: img/post-bg-bigsmall.png
catalog: true
tags:
    - PowerBI
---

前些天的文章中阐述了使用参数的改变来实现本地desktop创建模型、修改模型使用小的数据集，而云端service刷新使用大的数据集：

[Power bi 以小易大 破电脑也能搞定大模型 - 学谦PowerBI (powerbipro.cn)](http://powerbipro.cn/2022/05/16/Power-BI-以小易大-破电脑也能搞定大模型/)

获取的是本地文件夹中的文件。今天来说一说其他的数据来源。

SharePoint，或者Onedrive for Business

并且，上一篇文章中的方法，其实每次更新模型之后都需要在网页端进行修改参数，有些麻烦。因此本文也将重点说明如何让数据集自动在本地desktop中刷新小数据集，上了云之后刷新大数据集。



设置过程：



导航之后，每个table也就是一个文件夹中包含很多的文件：

![image-20220517211446345](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517211446345.png)



接下来我们的目的已经非常明确了，我们要实现的是：

在本地desktop刷新时，只保留【数据表-小】；在云端service刷新时， 只保留【数据表】

那么问题来了，如何实现？

可以先思考一下。

这里给出一个实现该目标的终极提示：

本地desktop刷新与云端service刷新时有什么不一样？

有没有什么函数返回结果是不同的？

答案揭晓：

![image-20220517213107503](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517213107503.png)

对，就是时区！
我们将这个8给提取出来：

![image-20220517213737546](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517213737546.png)

报告中显示：

![image-20220517213813442](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517213813442.png)

云端刷新一下：

![image-20220517214105307](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517214105307.png)

好了！

我们找到了一个云端和本地刷新时的不同点了，接下来就可以通过这两个数字的不同去筛选不同的表了！

添加一个自定义列，【数据表-小】对应0，【数据表】对应8：

![image-20220517214305106](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517214305106.png)

经过几步条件设置可以得到本地刷新时【数据表-小】对应1，【数据表】对应0，而这一数值在云端刷新时刚好反过来：

![image-20220517214540227](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517214540227.png)

筛选1，然后展开与合并表即可：

![image-20220517214817730](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517214817730.png)



本地刷新与云端刷新时两个表对应的【是否刷新】值：

![image-20220517215029826](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517215029826.png)



由于只有2个表2万多行，本地刷新很快：

![image-20220517215319825](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517215319825.png)



大数据集有270个文件，每个文件1万多行：

![image-20220517215258594](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517215258594.png)



最后一次刷新的时间就是云端自动刷新了大数据集，花了6分钟：

![image-20220517215400509](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517215400509.png)

因为数据量确实比较大：

![image-20220517215452794](https://picgo-1301351990.cos.ap-beijing.myqcloud.com/markdown/image-20220517215452794.png)







